<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>A Gentleman and a Scala</title>
 <link href="http://jliszka.github.io/" rel="self"/>
 <link href="http://jliszka.github.io"/>
 <updated>2013-10-20T22:54:51-04:00</updated>
 <id>http://jliszka.github.io</id>
 <author>
   <name>Jason Liszka</name>
   <email>jliszka@alumni.cmu.edu</email>
 </author>

 
 <entry>
   <title>Impossible functions</title>
   <link href="http://jliszka.github.io/2013/10/19/impossible-functions.html"/>
   <updated>2013-10-19T00:00:00-04:00</updated>
   <id>http://jliszka.github.io/2013/10/19/impossible-functions</id>
   <content type="html">
    
      &lt;style type='text/css'&gt;
th {
  padding: 5px;
  border: 1px solid #ccc;
}
tbody tr:nth-child(odd) {
  background: #eee;
}
tbody tr:nth-child(even) {
  background: #fff;
}
&lt;/style&gt;
&lt;p&gt;I claim to have a function &lt;code&gt;H&lt;/code&gt; that maps any integer-valued function you give it to a different integer. That is, an injection from &lt;code&gt;Int =&amp;gt; Int&lt;/code&gt; to &lt;code&gt;Int&lt;/code&gt; that returns a different &lt;code&gt;Int&lt;/code&gt; for every function you give it.&lt;/p&gt;

&lt;p&gt;This is clearly impossible, since there are way more functions from integers to integers than there are integers. But I demand proof in the form of witnesses &lt;code&gt;f: Int =&amp;gt; Int&lt;/code&gt;, &lt;code&gt;g: Int =&amp;gt; Int&lt;/code&gt; and &lt;code&gt;n: Int&lt;/code&gt; such that &lt;code&gt;H(f) == H(g)&lt;/code&gt; and &lt;code&gt;f(n) != g(n)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Your job is to write a function &lt;code&gt;solve&lt;/code&gt; that takes a single argument &lt;code&gt;H: (Int =&amp;gt; Int) =&amp;gt; Int&lt;/code&gt; and returns &lt;code&gt;f&lt;/code&gt;, &lt;code&gt;g&lt;/code&gt; and &lt;code&gt;n&lt;/code&gt; as described above.&lt;/p&gt;

&lt;p&gt;One approach is to put together a mathematical proof that such an injection is impossible and try to extract a program from that proof à la the &lt;a href='http://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence'&gt;Curry-Howard isomorphism&lt;/a&gt;.&lt;/p&gt;

      &lt;a href="http://jliszka.github.io/2013/10/19/impossible-functions.html">Read more&lt;/a>
    
   </content>
 </entry>
 
 <entry>
   <title>Understanding A/B Test Analysis</title>
   <link href="http://jliszka.github.io/2013/10/10/understanding-a-b-test-analysis.html"/>
   <updated>2013-10-10T00:00:00-04:00</updated>
   <id>http://jliszka.github.io/2013/10/10/understanding-a-b-test-analysis</id>
   <content type="html">
    
      &lt;style type='text/css'&gt;
th {
  padding: 5px;
  border: 1px solid #ccc;
}
tbody tr:nth-child(odd) {
  background: #eee;
}
tbody tr:nth-child(even) {
  background: #fff;
}
.blue1 {
  color: #16f;
}
.blue2 {
  color: #51f;
}
&lt;/style&gt;
&lt;p&gt;This is a continuation of my &lt;a href='/2013/08/26/a-programmers-guide-to-the-central-limit-theorem.html'&gt;previous post on the Central Limit Theorem&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Say you&amp;#8217;re designing a new feature for your website and you can&amp;#8217;t decide which shade of blue to use. So you let your users decide by trying both — some users see &lt;span class='blue1'&gt;this shade&lt;/span&gt; and some users get &lt;span class='blue2'&gt;this one&lt;/span&gt;. Whichever group of users spends more time on the site will determine which color you end up going with.&lt;/p&gt;

&lt;p&gt;You run your experiment for a little while and collect the following data:&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Group&lt;/th&gt;&lt;th&gt;Shade of blue&lt;/th&gt;&lt;th&gt;# of users&lt;/th&gt;&lt;th&gt;Average time on site&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;A&lt;/td&gt;&lt;td style='text-align: left;'&gt;&lt;span class='blue1'&gt;this one&lt;/span&gt;&lt;/td&gt;&lt;td style='text-align: left;'&gt;1,028&lt;/td&gt;&lt;td style='text-align: left;'&gt;91.4 seconds&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: left;'&gt;B&lt;/td&gt;&lt;td style='text-align: left;'&gt;&lt;span class='blue2'&gt;this one&lt;/span&gt;&lt;/td&gt;&lt;td style='text-align: left;'&gt;1,015&lt;/td&gt;&lt;td style='text-align: left;'&gt;103.8 seconds&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;Looks like group B did better! But it&amp;#8217;s a small difference, how can you be sure it&amp;#8217;s significant? In other words, assuming that the shade of blue had no effect on the amount of time a user spends on the site, what is the probability that you would have observed a difference of 11.4 seconds? In &lt;em&gt;other&lt;/em&gt; other words, given the distribution of the amount of time different users spend on the site, if you draw 2 samples of 1,000 or so from this distribution, what is the probability that you would see a difference of 21.4 (or more) in the averages of the samples?&lt;/p&gt;

&lt;p&gt;Well, you would expect that that depends a lot on the distribution. Here is the distribution you observed:&lt;/p&gt;

      &lt;a href="http://jliszka.github.io/2013/10/10/understanding-a-b-test-analysis.html">Read more&lt;/a>
    
   </content>
 </entry>
 
 <entry>
   <title>How traffic actually works</title>
   <link href="http://jliszka.github.io/2013/10/01/how-traffic-actually-works.html"/>
   <updated>2013-10-01T00:00:00-04:00</updated>
   <id>http://jliszka.github.io/2013/10/01/how-traffic-actually-works</id>
   <content type="html">
    
      &lt;p&gt;Every so often &lt;a href='http://www.smartmotorist.com/traffic-and-safety-guideline/traffic-jams.html'&gt;this article&lt;/a&gt; makes the rounds and it annoys me. That isn&amp;#8217;t how traffic works and the proposed solutions won&amp;#8217;t fix anything. Maybe you can eliminate the annoying stop-and-go, but no one gets home any faster. In fact you can prove that you and everyone behind you get home strictly later than if you had just gone along with the stop-and-go traffic.&lt;/p&gt;

&lt;h3 id='the_facts'&gt;The facts&lt;/h3&gt;

&lt;p&gt;Here&amp;#8217;s how traffic works. First, we know from &lt;a href='http://www.fhwa.dot.gov/publications/research/operations/tft/chap2.pdf'&gt;empirical studies&lt;/a&gt; that drivers tend to maintain a minimum following distance, measured in seconds. It varies per driver, but typically it&amp;#8217;s somewhere between 1.5 and 2 seconds. That works out to a maximum theoretical flow rate of between 1,800 and 2,400 vehicles per lane per hour passing by a given point on the highway. Studies of actual highway traffic have measured flow rates as high as 2,000 vehicles per lane per hour, which works out to a following distance of 1.8 seconds. (I&amp;#8217;m just going to call it 2 seconds for the sake of round numbers.)&lt;/p&gt;

&lt;p&gt;The important fact: &lt;strong&gt;there is a limit to the number of cars that can pass by a given point on the highway in a given amount of time, and that limit is one car every 2 seconds, per lane&lt;/strong&gt;. So imagine you are in heavy traffic during rush hour. There are a certain number of cars in line in front of you. Let&amp;#8217;s pick a point on the road to call the front of the line — say, the point at which you plan to exit the highway. The line gets shorter by one car every 2 seconds. If there are 1,000 cars in front of you, it&amp;#8217;s going to take a minimum of 2,000 seconds for you to get to the front of the line. It doesn&amp;#8217;t matter whether people are kind and let cars merge in front of them, zipper-style. It doesn&amp;#8217;t matter how much stop-and-go there is. The simple fact is that it takes 2 seconds per car for you to get to the front of the line, and there are some cars in front of you that have to get there before you do.&lt;/p&gt;

      &lt;a href="http://jliszka.github.io/2013/10/01/how-traffic-actually-works.html">Read more&lt;/a>
    
   </content>
 </entry>
 
 <entry>
   <title>More backwards functions: Unevaluating polynomials</title>
   <link href="http://jliszka.github.io/2013/09/24/more-backwards-functions-unevaluating-polynomials.html"/>
   <updated>2013-09-24T00:00:00-04:00</updated>
   <id>http://jliszka.github.io/2013/09/24/more-backwards-functions-unevaluating-polynomials</id>
   <content type="html">
    
      &lt;p&gt;I have a function that evaluates polynomials with integer coefficients. To evaluate &lt;script type='math/tex; mode=display'&gt;
%&lt;![CDATA[
f(x) = 6 + 5x + 2x^3
%]]&gt;
&lt;/script&gt; at &lt;script type='math/tex'&gt;f(8)&lt;/script&gt;, for example, you do this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scala&amp;gt; evalPoly(8, List(6, 5, 0, 2))
res0: (Int, Int) = (8, 1070)&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For some reason it echoes the input back out to you. Here&amp;#8217;s the code you might write:&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='scala'&gt;&lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;evalPoly&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;x&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;Int&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='n'&gt;coeffs&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;List&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;Int&lt;/span&gt;&lt;span class='p'&gt;])&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='kt'&gt;Int&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='kt'&gt;Int&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
  &lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;eval&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;cs&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;List&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;Int&lt;/span&gt;&lt;span class='p'&gt;])&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;Int&lt;/span&gt; &lt;span class='p'&gt;= {&lt;/span&gt;
    &lt;span class='n'&gt;cs&lt;/span&gt; &lt;span class='k'&gt;match&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
      &lt;span class='k'&gt;case&lt;/span&gt; &lt;span class='nc'&gt;Nil&lt;/span&gt; &lt;span class='k'&gt;=&amp;gt;&lt;/span&gt; &lt;span class='mi'&gt;0&lt;/span&gt;
      &lt;span class='k'&gt;case&lt;/span&gt; &lt;span class='n'&gt;h&lt;/span&gt; &lt;span class='o'&gt;::&lt;/span&gt; &lt;span class='n'&gt;t&lt;/span&gt; &lt;span class='k'&gt;=&amp;gt;&lt;/span&gt; &lt;span class='n'&gt;x&lt;/span&gt; &lt;span class='o'&gt;*&lt;/span&gt; &lt;span class='n'&gt;eval&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;t&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt; &lt;span class='o'&gt;+&lt;/span&gt; &lt;span class='n'&gt;h&lt;/span&gt;
    &lt;span class='p'&gt;}&lt;/span&gt;
  &lt;span class='p'&gt;}&lt;/span&gt;
  &lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;x&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='n'&gt;eval&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;coeffs&lt;/span&gt;&lt;span class='p'&gt;))&lt;/span&gt;
&lt;span class='p'&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This should not be surprising.&lt;/p&gt;

&lt;p&gt;But I also have a function that un-evaluates polynomials. To un-evaluate &lt;script type='math/tex'&gt;f(8) = 1070&lt;/script&gt;, you do this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scala&amp;gt; unevalPoly(8, 1070)
res1: (Int, List[Int]) = (8, List(6, 5, 0, 2))&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and it echoes your input and gives you back the coefficients of the polynomial.&lt;/p&gt;

      &lt;a href="http://jliszka.github.io/2013/09/24/more-backwards-functions-unevaluating-polynomials.html">Read more&lt;/a>
    
   </content>
 </entry>
 
 <entry>
   <title>Insertion sort is dual to bubble sort</title>
   <link href="http://jliszka.github.io/2013/09/18/insertion-sort-is-dual-to-bubble-sort.html"/>
   <updated>2013-09-18T00:00:00-04:00</updated>
   <id>http://jliszka.github.io/2013/09/18/insertion-sort-is-dual-to-bubble-sort</id>
   <content type="html">
    
      &lt;p&gt;I noticed recently that &lt;a href='http://en.wikipedia.org/wiki/insertion_sort'&gt;insertion sort&lt;/a&gt; is &lt;a href='http://en.wikipedia.org/wiki/Bubble_sort'&gt;bubble sort&lt;/a&gt; backwards. Or inside out. Or something.&lt;/p&gt;

&lt;p&gt;Both algorithms can be expressed as a main function that calls a recursive helper. Let&amp;#8217;s take a look at the main functions first.&lt;/p&gt;

&lt;h3 id='the_main_functions'&gt;The main functions&lt;/h3&gt;

&lt;p&gt;Here&amp;#8217;s the code:&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='scala'&gt;&lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;insertionSort&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;A&lt;/span&gt; &lt;span class='k'&gt;&amp;lt;:&lt;/span&gt; &lt;span class='kt'&gt;Ordered&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;A&lt;/span&gt;&lt;span class='p'&gt;]](&lt;/span&gt;&lt;span class='n'&gt;xs&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;List&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;A&lt;/span&gt;&lt;span class='p'&gt;])&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;List&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;A&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
  &lt;span class='n'&gt;xs&lt;/span&gt; &lt;span class='k'&gt;match&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
    &lt;span class='k'&gt;case&lt;/span&gt; &lt;span class='nc'&gt;Nil&lt;/span&gt; &lt;span class='k'&gt;=&amp;gt;&lt;/span&gt; &lt;span class='nc'&gt;Nil&lt;/span&gt;
    &lt;span class='k'&gt;case&lt;/span&gt; &lt;span class='n'&gt;h&lt;/span&gt; &lt;span class='o'&gt;::&lt;/span&gt; &lt;span class='n'&gt;t&lt;/span&gt; &lt;span class='k'&gt;=&amp;gt;&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
      &lt;span class='k'&gt;val&lt;/span&gt; &lt;span class='n'&gt;s&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='n'&gt;insertionSort&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;t&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
      &lt;span class='n'&gt;insert&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;h&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='n'&gt;s&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
    &lt;span class='p'&gt;}&lt;/span&gt;
  &lt;span class='p'&gt;}&lt;/span&gt;
&lt;span class='p'&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;insertionSort&lt;/code&gt; sorts a list by inserting the head of the list into the recursively sorted tail, in such a way that it remains sorted.&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='scala'&gt;&lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;bubbleSort&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;A&lt;/span&gt; &lt;span class='k'&gt;&amp;lt;:&lt;/span&gt; &lt;span class='kt'&gt;Ordered&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;A&lt;/span&gt;&lt;span class='p'&gt;]](&lt;/span&gt;&lt;span class='n'&gt;xs&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;List&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;A&lt;/span&gt;&lt;span class='p'&gt;])&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;List&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;A&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
  &lt;span class='n'&gt;xs&lt;/span&gt; &lt;span class='k'&gt;match&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
    &lt;span class='k'&gt;case&lt;/span&gt; &lt;span class='nc'&gt;Nil&lt;/span&gt; &lt;span class='k'&gt;=&amp;gt;&lt;/span&gt; &lt;span class='nc'&gt;Nil&lt;/span&gt;
    &lt;span class='k'&gt;case&lt;/span&gt; &lt;span class='n'&gt;xs&lt;/span&gt; &lt;span class='k'&gt;=&amp;gt;&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
      &lt;span class='k'&gt;val&lt;/span&gt; &lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;h&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='n'&gt;t&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='n'&gt;bubble&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;xs&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
      &lt;span class='k'&gt;val&lt;/span&gt; &lt;span class='n'&gt;s&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='n'&gt;bubbleSort&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;t&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
      &lt;span class='n'&gt;h&lt;/span&gt; &lt;span class='o'&gt;::&lt;/span&gt; &lt;span class='n'&gt;s&lt;/span&gt;
    &lt;span class='p'&gt;}&lt;/span&gt;
  &lt;span class='p'&gt;}&lt;/span&gt;  
&lt;span class='p'&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;bubbleSort&lt;/code&gt; sorts a list by bubbling the smallest element to the front of the list and recursively sorting the tail.&lt;/p&gt;

&lt;p&gt;It&amp;#8217;s not obvious from the code that these functions are backwards versions of each other, but look at their data flow diagrams:&lt;/p&gt;

      &lt;a href="http://jliszka.github.io/2013/09/18/insertion-sort-is-dual-to-bubble-sort.html">Read more&lt;/a>
    
   </content>
 </entry>
 
 <entry>
   <title>The 3 Things You Should Understand about Quantum Computation</title>
   <link href="http://jliszka.github.io/2013/09/09/the-3-things-you-should-understand-about-quantum-computing.html"/>
   <updated>2013-09-09T00:00:00-04:00</updated>
   <id>http://jliszka.github.io/2013/09/09/the-3-things-you-should-understand-about-quantum-computing</id>
   <content type="html">
    
      &lt;p&gt;I&amp;#8217;m working on a post about probablistic graphical models, but it&amp;#8217;s not done yet, so in the meantime here&amp;#8217;s a post about quantum probability.&lt;/p&gt;

&lt;h3 id='loaded_dice'&gt;Loaded dice&lt;/h3&gt;

&lt;p&gt;Let&amp;#8217;s say you have a loaded die with the following probability distribution:&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th /&gt;&lt;th /&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style='text-align: center;'&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/td&gt;&lt;td style='text-align: center;'&gt;10%&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: center;'&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt;&lt;td style='text-align: center;'&gt;20%&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: center;'&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/td&gt;&lt;td style='text-align: center;'&gt;30%&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: center;'&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;/td&gt;&lt;td style='text-align: center;'&gt;10%&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: center;'&gt;&lt;strong&gt;5&lt;/strong&gt;&lt;/td&gt;&lt;td style='text-align: center;'&gt;20%&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td style='text-align: center;'&gt;&lt;strong&gt;6&lt;/strong&gt;&lt;/td&gt;&lt;td style='text-align: center;'&gt;10%&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;How many pieces of information are encoded in a loaded die like this? It&amp;#8217;s weird to think of a probability distribution encoding information, but think of it this way: if you sent me this die in the mail, I could roll it a bunch of times to discover the probability for each face of the die. If you control how the die is weighted, you could send me a message that way.&lt;/p&gt;

&lt;p&gt;Anyway, the answer is that there are 5 pieces of information encoded in this distribution. (If you&amp;#8217;re not sure why it isn&amp;#8217;t 6, notice that once you specify 5 of the entries in the table, the 6th one is completely determined, since they all have to add up to 100%. So you can really only send me 5 numbers of your choosing this way.)&lt;/p&gt;

      &lt;a href="http://jliszka.github.io/2013/09/09/the-3-things-you-should-understand-about-quantum-computing.html">Read more&lt;/a>
    
   </content>
 </entry>
 
 <entry>
   <title>Fun with Bayesian Priors</title>
   <link href="http://jliszka.github.io/2013/09/03/fun-with-bayesian-priors.html"/>
   <updated>2013-09-03T00:00:00-04:00</updated>
   <id>http://jliszka.github.io/2013/09/03/fun-with-bayesian-priors</id>
   <content type="html">
    
      &lt;p&gt;Say you have a biased coin, but you don&amp;#8217;t know what the &amp;#8220;true&amp;#8221; bias is. You flip the coin 10 times and observe 8 heads. What can you say now about the true bias?&lt;/p&gt;

&lt;p&gt;It&amp;#8217;s easy to say that the most likely bias is 0.8. That&amp;#8217;s accurate, but maybe you also want to know what other biases are likely. How likely is it that you have a fair coin? Can you rule out having a bias as low as 0.4?&lt;/p&gt;

&lt;p&gt;This sounds like a classic problem in Bayesian inference, but I&amp;#8217;m going to take a different tack — simulation. To make this a little easier I&amp;#8217;ll use a &lt;a href='/2013/08/12/a-frequentist-approach-to-probability.html'&gt;Scala library based on the Monte Carlo method&lt;/a&gt; that I&amp;#8217;ve been working on as an exercise in trying to better understand &lt;a href='/2013/08/19/climbing-the-probability-distribution-ladder.html'&gt;some&lt;/a&gt; &lt;a href='/2013/08/26/a-programmers-guide-to-the-central-limit-theorem.html'&gt;ideas&lt;/a&gt; in probability and statistics.&lt;/p&gt;

&lt;h3 id='the_simulation'&gt;The simulation&lt;/h3&gt;

&lt;p&gt;A single trial in the simulation will look like this:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Choose a bias at random&lt;/li&gt;

&lt;li&gt;Flip a coin with that bias 10 times&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After, say, 10,000 trials, you look at all the times you got 8 heads, and see what the bias happened to be in each of those trials. The percent of the time each bias comes up in this subset of trials gives the probability (the &amp;#8220;posterior&amp;#8221; probability) that that bias is the &amp;#8220;true&amp;#8221; bias.&lt;/p&gt;

&lt;p&gt;When you start to code this up, one question jumps out: In step 1, when you choose a bias &amp;#8220;at random,&amp;#8221; what distribution do you draw it from?&lt;/p&gt;

      &lt;a href="http://jliszka.github.io/2013/09/03/fun-with-bayesian-priors.html">Read more&lt;/a>
    
   </content>
 </entry>
 
 <entry>
   <title>A Programmer's Guide to the Central Limit Theorem</title>
   <link href="http://jliszka.github.io/2013/08/26/a-programmers-guide-to-the-central-limit-theorem.html"/>
   <updated>2013-08-26T00:00:00-04:00</updated>
   <id>http://jliszka.github.io/2013/08/26/a-programmers-guide-to-the-central-limit-theorem</id>
   <content type="html">
    
      &lt;p&gt;This post is a continuation of a series of posts about exploring probability distributions through code. The first post is &lt;a href='/2013/08/12/a-frequentist-approach-to-probability.html'&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this post I&amp;#8217;m going to look at the Central Limit Theorem.&lt;/p&gt;

&lt;h3 id='sample_means'&gt;Sample means&lt;/h3&gt;

&lt;p&gt;Suppose I have a random variable whose underlying distribution is unknown to me. I take sample of a reasonable size (say 100) and find the mean of the sample. What can I say about the relationship between the true mean and the mean of the sample?&lt;/p&gt;

&lt;p&gt;The most comprehensive answer to this is to look at the distribution of the sample mean.&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='scala'&gt;&lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;sampleMean&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;d&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;Distribution&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;Double&lt;/span&gt;&lt;span class='p'&gt;],&lt;/span&gt; &lt;span class='n'&gt;n&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;Int&lt;/span&gt; &lt;span class='p'&gt;= &lt;/span&gt;&lt;span class='mi'&gt;100&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;Distribution&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;Double&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
  &lt;span class='n'&gt;d&lt;/span&gt;&lt;span class='p'&gt;.&lt;/span&gt;&lt;span class='n'&gt;repeat&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;n&lt;/span&gt;&lt;span class='p'&gt;).&lt;/span&gt;&lt;span class='n'&gt;map&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='k'&gt;_&lt;/span&gt;&lt;span class='p'&gt;.&lt;/span&gt;&lt;span class='n'&gt;sum&lt;/span&gt; &lt;span class='o'&gt;/&lt;/span&gt; &lt;span class='n'&gt;n&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
&lt;span class='p'&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This method takes a probability distribution and returns the distribution of means of samples from that distribution. You can specify the sample size, but by default we&amp;#8217;ll use 100.&lt;/p&gt;

&lt;p&gt;Let&amp;#8217;s try it on some of the distributions we&amp;#8217;ve &lt;a href='/2013/08/19/climbing-the-probability-distribution-ladder.html'&gt;created&lt;/a&gt;.&lt;/p&gt;

      &lt;a href="http://jliszka.github.io/2013/08/26/a-programmers-guide-to-the-central-limit-theorem.html">Read more&lt;/a>
    
   </content>
 </entry>
 
 <entry>
   <title>Climbing the probability distribution ladder</title>
   <link href="http://jliszka.github.io/2013/08/19/climbing-the-probability-distribution-ladder.html"/>
   <updated>2013-08-19T00:00:00-04:00</updated>
   <id>http://jliszka.github.io/2013/08/19/climbing-the-probability-distribution-ladder</id>
   <content type="html">
    
      &lt;p&gt;In the &lt;a href='/2013/08/12/a-frequentist-approach-to-probability.html'&gt;last post&lt;/a&gt; I created a simple library for constructing probability distributions, based on the &lt;a href='http://en.wikipedia.org/wiki/Monte_Carlo_method'&gt;Monte Carlo method&lt;/a&gt;. I started with the uniform distribution and derived the Bernoulli and normal distributions from it.&lt;/p&gt;

&lt;p&gt;In this post I&amp;#8217;ll construct some more common distributions in the same manner.&lt;/p&gt;

&lt;h3 id='the_exponential_distribution'&gt;The exponential distribution&lt;/h3&gt;

&lt;p&gt;If &lt;script type='math/tex'&gt;X&lt;/script&gt; is a uniformly distributed random variable, then &lt;script type='math/tex'&gt;-log(X)/\lambda&lt;/script&gt; is distributed according to the &lt;a href='http://en.wikipedia.org/wiki/Exponential_distribution'&gt;exponential distribution&lt;/a&gt;. The parameter &lt;script type='math/tex'&gt;\lambda&lt;/script&gt; is just a scaling factor. In code:&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='scala'&gt;&lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;exponential&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;l&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;Double&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;Distribution&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;Double&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
  &lt;span class='k'&gt;for&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
    &lt;span class='n'&gt;x&lt;/span&gt; &lt;span class='k'&gt;&amp;lt;-&lt;/span&gt; &lt;span class='n'&gt;uniform&lt;/span&gt;
  &lt;span class='p'&gt;}&lt;/span&gt; &lt;span class='k'&gt;yield&lt;/span&gt; &lt;span class='n'&gt;math&lt;/span&gt;&lt;span class='p'&gt;.&lt;/span&gt;&lt;span class='n'&gt;log&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;x&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt; &lt;span class='o'&gt;*&lt;/span&gt; &lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='o'&gt;-&lt;/span&gt;&lt;span class='mi'&gt;1&lt;/span&gt;&lt;span class='o'&gt;/&lt;/span&gt;&lt;span class='n'&gt;l&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
&lt;span class='p'&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It looks like this:&lt;/p&gt;

      &lt;a href="http://jliszka.github.io/2013/08/19/climbing-the-probability-distribution-ladder.html">Read more&lt;/a>
    
   </content>
 </entry>
 
 <entry>
   <title>A Frequentist Approach to Probability</title>
   <link href="http://jliszka.github.io/2013/08/12/a-frequentist-approach-to-probability.html"/>
   <updated>2013-08-12T00:00:00-04:00</updated>
   <id>http://jliszka.github.io/2013/08/12/a-frequentist-approach-to-probability</id>
   <content type="html">
    
      &lt;p&gt;One thing that always confused me in my intro stats classes was the concept of a random variable. A random variable is not a variable like I&amp;#8217;m used to thinking about, like a thing that has one value at a time. A random variable is instead an object that you can sample values from, and the values you get will be distributed according to some underlying probability distribution.&lt;/p&gt;

&lt;p&gt;In that way it sort of acts like a container, where the only operation is to sample a value from the container. In Scala it might look something like:&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='scala'&gt;&lt;span class='k'&gt;trait&lt;/span&gt;&lt;span class='kd'&gt; &lt;/span&gt;&lt;span class='nc'&gt;Distribution&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;A&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
  &lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;get&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;A&lt;/span&gt;
&lt;span class='p'&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The idea is that &lt;code&gt;get&lt;/code&gt; returns a different value (of type &lt;code&gt;A&lt;/code&gt;) from the distribution every time you call it.&lt;/p&gt;

&lt;p&gt;I&amp;#8217;m going to add a &lt;code&gt;sample&lt;/code&gt; method that lets me draw a sample of any size I want from the distribution.&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='scala'&gt;&lt;span class='k'&gt;trait&lt;/span&gt;&lt;span class='kd'&gt; &lt;/span&gt;&lt;span class='nc'&gt;Distribution&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;A&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
  &lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;get&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;A&lt;/span&gt;

  &lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;sample&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;n&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;Int&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;List&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;A&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
    &lt;span class='nc'&gt;List&lt;/span&gt;&lt;span class='p'&gt;.&lt;/span&gt;&lt;span class='n'&gt;fill&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;n&lt;/span&gt;&lt;span class='p'&gt;)(&lt;/span&gt;&lt;span class='k'&gt;this&lt;/span&gt;&lt;span class='p'&gt;.&lt;/span&gt;&lt;span class='n'&gt;get&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
  &lt;span class='p'&gt;}&lt;/span&gt;
&lt;span class='p'&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now to create a simple distribution. Here&amp;#8217;s one whose samples are uniformly distributed between 0 and 1.&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='scala'&gt;&lt;span class='k'&gt;val&lt;/span&gt; &lt;span class='n'&gt;uniform&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='k'&gt;new&lt;/span&gt; &lt;span class='nc'&gt;Distribution&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;Double&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
  &lt;span class='k'&gt;private&lt;/span&gt; &lt;span class='k'&gt;val&lt;/span&gt; &lt;span class='n'&gt;rand&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='k'&gt;new&lt;/span&gt; &lt;span class='n'&gt;java&lt;/span&gt;&lt;span class='p'&gt;.&lt;/span&gt;&lt;span class='n'&gt;util&lt;/span&gt;&lt;span class='p'&gt;.&lt;/span&gt;&lt;span class='nc'&gt;Random&lt;/span&gt;&lt;span class='p'&gt;()&lt;/span&gt;
  &lt;span class='k'&gt;override&lt;/span&gt; &lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;get&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='n'&gt;rand&lt;/span&gt;&lt;span class='p'&gt;.&lt;/span&gt;&lt;span class='n'&gt;nextDouble&lt;/span&gt;&lt;span class='p'&gt;()&lt;/span&gt;
&lt;span class='p'&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And sampling it gives&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scala&amp;gt; uniform.sample(10).foreach(println)
0.15738645964157327
0.7827120503875181
0.8787176537434814
0.38506604599728245
0.9469681837641953
0.20822217752687067
0.8229649049912187
0.7767540566158817
0.4133782959276152
0.8152378840945975&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id='transforming_distributions'&gt;Transforming distributions&lt;/h3&gt;

&lt;p&gt;Every good container should have a &lt;code&gt;map&lt;/code&gt; method. &lt;code&gt;map&lt;/code&gt; will transform values produced by the distribution according to some function you pass it.&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='scala'&gt;&lt;span class='k'&gt;trait&lt;/span&gt;&lt;span class='kd'&gt; &lt;/span&gt;&lt;span class='nc'&gt;Distribution&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;A&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
  &lt;span class='n'&gt;self&lt;/span&gt; &lt;span class='k'&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class='c1'&gt;// ...&lt;/span&gt;
  &lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;map&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;B&lt;/span&gt;&lt;span class='p'&gt;](&lt;/span&gt;&lt;span class='n'&gt;f&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;A&lt;/span&gt; &lt;span class='kt'&gt;=&amp;gt;&lt;/span&gt; &lt;span class='kt'&gt;B&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;&lt;span class='k'&gt;:&lt;/span&gt; &lt;span class='kt'&gt;Distribution&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;B&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='k'&gt;new&lt;/span&gt; &lt;span class='nc'&gt;Distribution&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='kt'&gt;B&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
    &lt;span class='k'&gt;override&lt;/span&gt; &lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;get&lt;/span&gt; &lt;span class='k'&gt;=&lt;/span&gt; &lt;span class='n'&gt;f&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;self&lt;/span&gt;&lt;span class='p'&gt;.&lt;/span&gt;&lt;span class='n'&gt;get&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
  &lt;span class='p'&gt;}&lt;/span&gt;
&lt;span class='p'&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      &lt;a href="http://jliszka.github.io/2013/08/12/a-frequentist-approach-to-probability.html">Read more&lt;/a>
    
   </content>
 </entry>
 
 
</feed>