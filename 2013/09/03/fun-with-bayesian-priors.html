
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Fun with Bayesian Priors</title>
    <meta name="description" content="">
    <meta name="author" content="Jason Liszka">

    <!-- Enable responsive viewport -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.2.2.2.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css?body=1&amp;v=2" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/twitter/css/pygment.css" rel="stylesheet" type="text/css" media="all">

    <!-- Le fav and touch icons -->
  <!-- Update these with your own images
    <link rel="shortcut icon" href="images/favicon.ico">
    <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
  -->

    <!-- atom & rss feed -->
    <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  </head>

  <body>
    <div class="navbar">
      <div class="navbar-inner">
        <div class="container-narrow">
          <div class="row-fluid">
            <div class="span9 offset1">
              <a class="brand" href="/">A Gentleman and a Scala</a>
              <ul class="nav">
                
                
                


  
    
      
      	
      	<li><a href="/archive.html">Archive</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/tags.html">Tags</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  



              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-narrow">

      <div class="content">
        
<div class="row-fluid">
  <div class="span9 offset1 post-content post-spacer"></div>
</div>
<div class="row-fluid post-full">
  <div class="span9 offset1 post-content">
    <div class="page-header">
      <h1>Fun with Bayesian Priors </h1>
    </div>
    <div class="date">
      <span>03 September 2013</span>
    </div>
    <div class="content">
      
<p>Say you have a biased coin, but you don’t know what the “true” bias is. You flip the coin
10 times and observe 8 heads. What can you say now about the true bias?</p>

<p>It’s easy to say that the most likely bias is 0.8. That’s accurate, but maybe you also want to know what other
biases are likely. How likely is it that you have a fair coin? Can you rule out having a bias as low as 0.4?</p>

<p>This sounds like a classic problem in Bayesian inference, but I’m going to take a different tack — simulation.
To make this a little easier I’ll use a <a href="/2013/08/12/a-frequentist-approach-to-probability.html">Scala library based on the Monte Carlo method</a>
that I’ve been working on as an exercise in trying to better understand <a href="/2013/08/19/climbing-the-probability-distribution-ladder.html">some</a>
<a href="/2013/08/26/a-programmers-guide-to-the-central-limit-theorem.html">ideas</a> in probability and statistics.</p>

<h3 id="the-simulation">The simulation</h3>

<p>A single trial in the simulation will look like this:</p>

<ol>
  <li>Choose a bias at random</li>
  <li>Flip a coin with that bias 10 times</li>
</ol>

<p>After, say, 10,000 trials, you look at all the times you got 8 heads, and see what the bias happened to be in each of those
trials. The percent of the time each bias comes up in this subset of trials gives the probability
(the “posterior” probability) that that bias is the “true” bias.</p>

<p>When you start to code this up, one question jumps out:
In step 1, when you choose a bias “at random,” what distribution do you draw it from?</p>

<!-- more -->

<p>The most reasonable choice is the uniform distribution between 0 and 1. This makes sense if you want to
assume no particular prior knowledge about what the true bias is — all biases are equally likely.
Later on we’ll see what happens to the posterior distribution when you start with different distributions representing
prior knowledge about the bias (commonly just called the “prior”).</p>

<p>So first, we’ll need a case class that represents the outcome of one trial:</p>

<div class="highlight"><pre><code class="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">Trial</span><span class="o">(</span><span class="n">bias</span><span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">heads</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span></code></pre></div>

<p>And here’s the simulation itself:</p>

<div class="highlight"><pre><code class="scala"><span class="k">val</span> <span class="n">experiment</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">Trial</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">for</span> <span class="o">{</span>
    <span class="n">bias</span> <span class="k">&lt;-</span> <span class="n">uniform</span>
    <span class="n">heads</span> <span class="k">&lt;-</span> <span class="n">binomial</span><span class="o">(</span><span class="n">bias</span><span class="o">,</span> <span class="mi">10</span><span class="o">)</span>
  <span class="o">}</span> <span class="k">yield</span> <span class="nc">Trial</span><span class="o">(</span><span class="n">bias</span><span class="o">,</span> <span class="n">heads</span><span class="o">)</span>
<span class="o">}</span></code></pre></div>

<p>(I recommend reading <a href="/2013/08/12/a-frequentist-approach-to-probability.html">this writeup of the probability distribution monad</a>
if you haven’t seen this before.)</p>

<p>The bias is drawn from the uniform distribution, and a <a href="/2013/08/19/climbing-the-probability-distribution-ladder.html">binomial distribution</a> represents the number of
heads you will see in 10 coin flips when the probability of seeing a head on a single coin flip is determined by the value of <code>bias</code>.</p>

<p>Now let’s analyze the experiment. Remember we only care about the trials that resulted in 8 heads.</p>

<div class="highlight"><pre><code class="scala"><span class="k">val</span> <span class="n">posterior</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="n">experiment</span><span class="o">.</span><span class="n">given</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">heads</span> <span class="o">==</span> <span class="mi">8</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">bias</span><span class="o">)</span>
<span class="o">}</span></code></pre></div>

<p>Let’s see what it looks like:</p>

<pre><code>scala&gt; posterior.bucketedHist(0, 1, 20)
0.00  0.00% 
0.05  0.00% 
0.10  0.00% 
0.15  0.00% 
0.20  0.01% 
0.25  0.03% 
0.30  0.09% 
0.35  0.18% 
0.40  0.63% 
0.45  1.37% #
0.50  2.32% ##
0.55  3.85% ###
0.60  6.69% ######
0.65  9.35% #########
0.70 12.73% ############
0.75 15.49% ###############
0.80 16.91% ################
0.85 15.08% ###############
0.90 10.60% ##########
0.95  4.48% ####
1.00  0.19% 
</code></pre>

<p>That looks pretty good! It’s clear that 0.8 is the most likely bias, as expected.</p>

<h3 id="chaining-posteriors">Chaining posteriors</h3>

<p>Alright, now suppose you flip the same coin 10 more times and get only 6 heads. This can be modeled
the same way, only this time, instead of using <code>uniform</code> as the prior distribution for the bias, you can use
<code>posterior</code>, essentially building on top of our new belief about what the bias is from the first experiment.</p>

<div class="highlight"><pre><code class="scala"><span class="k">val</span> <span class="n">experiment2</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">for</span> <span class="o">{</span>
    <span class="n">bias</span> <span class="k">&lt;-</span> <span class="n">posterior</span>
    <span class="n">heads</span> <span class="k">&lt;-</span> <span class="n">binomial</span><span class="o">(</span><span class="n">bias</span><span class="o">,</span> <span class="mi">10</span><span class="o">)</span>
  <span class="o">}</span> <span class="k">yield</span> <span class="nc">Trial</span><span class="o">(</span><span class="n">bias</span><span class="o">,</span> <span class="n">heads</span><span class="o">)</span>
<span class="o">}</span>
<span class="k">val</span> <span class="n">posterior2</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="n">experiment2</span><span class="o">.</span><span class="n">given</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">heads</span> <span class="o">==</span> <span class="mi">6</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">bias</span><span class="o">)</span>
<span class="o">}</span></code></pre></div>

<pre><code>scala&gt; posterior2.bucketedHist(0, 1, 20)
0.00  0.00% 
0.05  0.00% 
0.10  0.00% 
0.15  0.00% 
0.20  0.00% 
0.25  0.00% 
0.30  0.00% 
0.35  0.18% 
0.40  0.55% 
0.45  1.84% #
0.50  4.25% ####
0.55  7.79% #######
0.60 12.91% ############
0.65 17.86% #################
0.70 19.41% ###################
0.75 17.66% #################
0.80 11.37% ###########
0.85  4.98% ####
0.90  1.14% #
0.95  0.06% 
1.00  0.00% 
</code></pre>

<p>Great, exactly what you would expect. The distribution has shifted towards 0.7 (14/20) and has narrowed a bit.</p>

<h3 id="i-cant-not-abstract-this-out-into-a-method">I can’t not abstract this out into a method</h3>

<p>I’ve written almost the exact same code twice, so I basically have to do this now.
Here’s my attempt, as an instance method of the <code>Distribution</code> interface:</p>

<div class="highlight"><pre><code class="scala"><span class="k">trait</span> <span class="nc">Distribution</span><span class="o">[</span><span class="kt">A</span><span class="o">]</span> <span class="o">{</span>
  <span class="c1">// ...</span>
  <span class="k">def</span> <span class="n">posterior</span><span class="o">[</span><span class="kt">B</span><span class="o">](</span><span class="n">experiment</span><span class="k">:</span> <span class="kt">A</span> <span class="o">=&gt;</span> <span class="nc">Distribution</span><span class="o">[</span><span class="kt">B</span><span class="o">])</span>
                   <span class="o">(</span><span class="n">observed</span><span class="k">:</span> <span class="kt">B</span> <span class="o">=&gt;</span> <span class="nc">Boolean</span><span class="o">)</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">A</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">case</span> <span class="k">class</span> <span class="nc">Trial</span><span class="o">(</span><span class="n">a</span><span class="k">:</span> <span class="kt">A</span><span class="o">,</span> <span class="n">outcome</span><span class="k">:</span> <span class="kt">B</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">d</span> <span class="k">=</span> <span class="k">for</span> <span class="o">{</span>
      <span class="n">a</span> <span class="k">&lt;-</span> <span class="k">this</span>
      <span class="n">e</span> <span class="k">&lt;-</span> <span class="n">experiment</span><span class="o">(</span><span class="n">a</span><span class="o">)</span>
    <span class="o">}</span> <span class="k">yield</span> <span class="nc">Trial</span><span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">e</span><span class="o">)</span>
    <span class="n">d</span><span class="o">.</span><span class="n">given</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">observed</span><span class="o">(</span><span class="n">t</span><span class="o">.</span><span class="n">outcome</span><span class="o">)).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">a</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>

<p>The idea is that <code>posterior</code> updates a prior distribution according to the outcome of some experiment. It returns
the new posterior after running the provided <code>experiment</code>, which depends on values sampled from the prior, and in which only certain
outcomes are observed. The <code>observed</code> parameter is a function that indicates what outcomes were actually observed in the experiment
and which were not.</p>

<p>So now our first two experiments become:</p>

<div class="highlight"><pre><code class="scala"><span class="k">val</span> <span class="n">p1</span> <span class="k">=</span> <span class="n">uniform</span><span class="o">.</span><span class="n">posterior</span><span class="o">(</span><span class="n">bias</span> <span class="k">=&gt;</span> <span class="n">binomial</span><span class="o">(</span><span class="n">bias</span><span class="o">,</span> <span class="mi">10</span><span class="o">))(</span><span class="k">_</span> <span class="o">==</span> <span class="mi">8</span><span class="o">)</span>
<span class="k">val</span> <span class="n">p2</span> <span class="k">=</span> <span class="n">p1</span><span class="o">.</span><span class="n">posterior</span><span class="o">(</span><span class="n">bias</span> <span class="k">=&gt;</span> <span class="n">binomial</span><span class="o">(</span><span class="n">bias</span><span class="o">,</span> <span class="mi">10</span><span class="o">))(</span><span class="k">_</span> <span class="o">==</span> <span class="mi">6</span><span class="o">)</span></code></pre></div>

<p>Pretty clean!</p>

<p>We can eyeball that <code>p2</code> gives the same result as flipping a coin 20 times and observing 14 heads:</p>

<pre><code>scala&gt; uniform.posterior(bias =&gt; binomial(bias, 20))(_ == 14).bucketedHist(0, 1, 20)
0.00  0.00% 
0.05  0.00% 
0.10  0.00% 
0.15  0.00% 
0.20  0.00% 
0.25  0.00% 
0.30  0.06% 
0.35  0.13% 
0.40  0.53% 
0.45  1.83% #
0.50  3.88% ###
0.55  8.20% ########
0.60 13.40% #############
0.65 17.61% #################
0.70 19.28% ###################
0.75 18.30% ##################
0.80 11.33% ###########
0.85  4.40% ####
0.90  0.98% 
0.95  0.07% 
1.00  0.00% 
</code></pre>

<p>And that more trials gives a narrower distribution:</p>

<pre><code>scala&gt; uniform.posterior(bias =&gt; binomial(bias, 100))(_ == 72).bucketedHist(0, 1, 20)
0.00  0.00% 
0.05  0.00% 
0.10  0.00% 
0.15  0.00% 
0.20  0.00% 
0.25  0.00% 
0.30  0.00% 
0.35  0.00% 
0.40  0.00% 
0.45  0.00% 
0.50  0.01% 
0.55  0.14% 
0.60  2.35% ##
0.65 15.58% ###############
0.70 39.42% #######################################
0.75 33.53% #################################
0.80  8.60% ########
0.85  0.37% 
0.90  0.00% 
0.95  0.00% 
1.00  0.00% 
</code></pre>

<p>Neat!</p>

<h3 id="does-the-posterior-distribution-have-a-memory">Does the posterior distribution have a memory?</h3>

<p>My intuition says that if I flip a coin 10 times and get 2 heads (20%), and then flip it 30 times and get 3 heads (10%),
the combined posterior should say that the most likely bias is somewhere between 20% and 10%,
but closer to 10% because the 30 flips should count more than the 10 flips.
In fact it should be exactly 12.5% since we observed 5 total heads in 40 total flips.</p>

<p>But does this technique of chaining posteriors actually give that result?
After I generate the first posterior distribution from the 10-flip experiment, isn’t the information that I flipped it 10 times lost somehow?
Let’s see.</p>

<pre><code>scala&gt; val p1 = uniform.posterior(bias =&gt; binomial(bias, 10))(_ == 2)
p1: Distribution[Double] = &lt;distribution&gt;

scala&gt; p1.bucketedHist(0, 1, 20)
0.00  0.28% 
0.05  4.14% ####
0.10 10.45% ##########
0.15 15.02% ###############
0.20 16.38% ################
0.25 15.37% ###############
0.30 12.85% ############
0.35  9.65% #########
0.40  6.68% ######
0.45  4.30% ####
0.50  2.54% ##
0.55  1.37% #
0.60  0.58% 
0.65  0.27% 
0.70  0.10% 
0.75  0.02% 
0.80  0.00% 
0.85  0.00% 
0.90  0.00% 
0.95  0.00% 
1.00  0.00% 

scala&gt; val p2 = p1.posterior(bias =&gt; binomial(bias, 30))(_ == 3)
p2: Distribution[Double] = &lt;distribution&gt;

scala&gt; p2.bucketedHist(0, 0.5, 20)
0.000  0.00% 
0.025  0.41% 
0.050  3.89% ###
0.075 10.21% ##########
0.100 16.69% ################
0.125 18.80% ##################
0.150 17.77% #################
0.175 12.85% ############
0.200  9.02% #########
0.225  5.06% #####
0.250  2.93% ##
0.275  1.46% #
0.300  0.44% 
0.325  0.37% 
0.350  0.04% 
0.375  0.04% 
0.400  0.02% 
0.425  0.00% 
0.450  0.00% 
0.475  0.00% 
0.500  0.00% 
</code></pre>

<p>Hm, yeah, it sure looks like it worked! The most likely bias is 12.5%.</p>

<p>So how does this work? Well, <code>p1</code> actually does encode how many flips went into it — more flips translates into a narrower
distribution, and fewer flips will produce a distribution that is more spread out.
This is pretty easily illustrated: if instead we had done 20 flips and gotten 4 heads, or 40 flips
and gotten 8 heads, the resulting posterior distributions would have looked different, even though these each encode the same
20% bias.</p>

<pre><code>scala&gt; uniform.posterior(bias =&gt; binomial(bias, 20))(_ == 4).bucketedHist(0, 1, 20)
0.00  0.00% 
0.05  1.61% #
0.10  9.57% #########
0.15 18.74% ##################
0.20 22.51% ######################
0.25 19.40% ###################
0.30 14.06% ##############
0.35  8.03% ########
0.40  3.84% ###
0.45  1.57% #
0.50  0.48% 
0.55  0.13% 
0.60  0.06% 
0.65  0.00% 
0.70  0.00% 
0.75  0.00% 
0.80  0.00% 
0.85  0.00% 
0.90  0.00% 
0.95  0.00% 
1.00  0.00% 

scala&gt; uniform.posterior(bias =&gt; binomial(bias, 40))(_ == 8).bucketedHist(0, 1, 20)
0.00  0.00% 
0.05  0.39% 
0.10  6.15% ######
0.15 22.06% ######################
0.20 30.70% ##############################
0.25 23.72% #######################
0.30 12.06% ############
0.35  3.85% ###
0.40  0.90% 
0.45  0.16% 
0.50  0.01% 
0.55  0.00% 
0.60  0.00% 
0.65  0.00% 
0.70  0.00% 
0.75  0.00% 
0.80  0.00% 
0.85  0.00% 
0.90  0.00% 
0.95  0.00% 
1.00  0.00% 
</code></pre>

<p>The shape of the prior distribution naturally affects the posteriors that result from it.</p>

<h3 id="fun-with-priors">Fun with priors</h3>

<p>Let’s see exactly how that plays out by feeding in different priors and see what posterior distributions come out.</p>

<p>Suppose we start with some knowledge that coin favors tails over heads. So we know the bias is less than 0.5.
We’ll model this with a uniform distribution between 0 and 0.5.</p>

<pre><code>scala&gt; val prior = uniform.given(_ &lt; 0.5)
prior: Distribution[Double] = &lt;distribution&gt;

scala&gt; prior.posterior(bias =&gt; binomial(bias, 10))(_ == 8).bucketedHist(0, 1, 20, roundDown = true)
0.00  0.00% 
0.05  0.00% 
0.10  0.00% 
0.15  0.01% 
0.20  0.33% 
0.25  1.47% #
0.30  4.42% ####
0.35 11.61% ###########
0.40 26.93% ##########################
0.45 55.23% #######################################################
0.50  0.00% 
0.55  0.00% 
0.60  0.00% 
0.65  0.00% 
0.70  0.00% 
0.75  0.00% 
0.80  0.00% 
0.85  0.00% 
0.90  0.00% 
0.95  0.00% 
1.00  0.00% 
</code></pre>

<p>Makes sense, all the probabily mass crowds as close to 0.5 as it can.</p>

<p>Now let’s try something a little silly — say someone tells us that they don’t know what the bias is, but it is
definitely <em>not</em> between 0.7 and 0.8.</p>

<pre><code>scala&gt; val prior = uniform.given(x =&gt; x &lt;= 0.7 || x &gt;= 0.8)
prior: Distribution[Double] = &lt;distribution&gt;

scala&gt; prior.posterior(bias =&gt; binomial(bias, 10))(_ == 8).bucketedHist(0, 1, 20, roundDown = true)
0.00  0.00% 
0.05  0.00% 
0.10  0.00% 
0.15  0.00% 
0.20  0.03% 
0.25  0.02% 
0.30  0.20% 
0.35  0.39% 
0.40  1.21% #
0.45  2.79% ##
0.50  4.67% ####
0.55  7.52% #######
0.60 11.68% ###########
0.65 16.20% ################
0.70  0.00% 
0.75  0.00% 
0.80 23.96% #######################
0.85 18.53% ##################
0.90 10.52% ##########
0.95  2.28% ##
1.00  0.00% 
</code></pre>

<p>Fun! Makes perfect sense though, the prior distribution isn’t generating any biases between 0.7 and 0.8, so it’s not going
to show up in the results.</p>

<p>Now let’s say we know the bias is either 0.5 or 0.9 (we either have a perfectly fair coin or a very biased coin). Our prior
is then:</p>

<pre><code>scala&gt; val prior = discreteUniform(List(0.5, 0.9))
prior: Distribution[Double] = &lt;distribution&gt;

scala&gt; prior.bucketedHist(0, 1, 10)
0.0  0.00% 
0.1  0.00% 
0.2  0.00% 
0.3  0.00% 
0.4  0.00% 
0.5 49.76% #################################################
0.6  0.00% 
0.7  0.00% 
0.8  0.00% 
0.9 50.24% ##################################################
1.0  0.00% 
</code></pre>

<p>Now after flipping the coin 10 times and observing 8 heads, the posterior becomes:</p>

<pre><code>scala&gt; prior.posterior(bias =&gt; binomial(bias, 10))(_ == 8).bucketedHist(0, 1, 10)
0.0  0.00% 
0.1  0.00% 
0.2  0.00% 
0.3  0.00% 
0.4  0.00% 
0.5 18.40% ##################
0.6  0.00% 
0.7  0.00% 
0.8  0.00% 
0.9 81.60% #################################################################################
1.0  0.00% 
</code></pre>

<h3 id="bayes-theorem">Bayes’ theorem</h3>

<p>It’s pretty easy to use Bayes’ theorem to analyze that last example, so let’s walk through it and compare.</p>

<p>Here’s the formula applied to this example:
<script type="math/tex; mode=display">
%&lt;![CDATA[
\begin{align}
  P(A|B) &amp;= \frac{P(B|A)P(A)}{P(B)}
  \\ P(\text{fair coin}|\text{8 heads})
     &amp;= \frac{P(\text{8 heads}|\text{fair coin})P(\text{fair coin})}{P(\text{8 heads})}
  \\ &amp;= \frac{P(\text{8 heads}|\text{fair coin})P(\text{fair coin})}{P(\text{8 heads}|\text{fair coin})P(\text{fair coin}) + P(\text{8 heads}|\text{biased coin})P(\text{biased coin})}
  \\ &amp;= \frac{ {10 \choose 8} (\frac{1}{2})^{10} \cdot \frac{1}{2}}
          { {10 \choose 8} (\frac{1}{2})^{10} \cdot \frac{1}{2} + {10 \choose 8} (\frac{9}{10})^8 (\frac{1}{10})^2 \cdot \frac{1}{2}}
  \\ &amp;= \frac{0.022}{0.022 + 0.097} = 0.18
\end{align}
%]]&gt;
</script></p>

<p>So we got the same result. Written out, you can see the correspondence between Bayes’ Theorem and our simulation.
<script type="math/tex">P(\text{fair coin})</script> and <script type="math/tex">P(\text{biased coin})</script> in the denominator play the same role as our prior
in regulating how often we’re using each bias. Then it becomes a simple fraction to determine the probability that
the coin is fair — it’s just the fraction of the number of times you observe 8 heads that are accounted for by using a fair coin.
There’s a slight mismatch here, in that this formula deals with probabilities, whereas I’m talking about the number of times you
observe certain outcomes. But this is easily enough explained — if you multiply the numerator and denominator by the
number of trials you plan on running, you will have converted the probabilities into numbers of successes in that many trials,
without changing the value of the fraction.</p>

<h3 id="conclusion">Conclusion</h3>

<p>In Bayesian probability, the prior distribution reflects your degree of belief that an unknown quantity takes on particular
values. It represents your uncertainty, rather than the relative frequencies of observing particular events, as is the case
with the frequentist interpretation of probability.</p>

<p>However, we’ve seen that the prior can acquiesce to a frequentist interpretation. We’ve essentially turned the
prior into a machine that regulates how often we’re allowed to see certain values of an unknown quantity in our experiments,
and the observed outcomes of experiments will be used to refine the output of the machine.</p>

    </div>

    

  


  <div style="float: right; margin-top: 5px">
  <a href="https://twitter.com/share" class="twitter-share-button" data-url="http://jliszka.github.io/2013/09/03/fun-with-bayesian-priors.html" data-text="Fun with Bayesian Priors" data-via="jliszka">Tweet</a>
  <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
</div>




  
    <ul class="tag_box inline">
      <li><i class="icon-tags"></i></li>
      
      


  
     
    	<li><a href="/tags.html#probability-ref">probability <span>9</span></a></li>
    
  



    </ul>
    
    <div style="clear: both"></div>

    <hr>
    <div class="navigation">
    
      <span class="prev"><a href="/2013/08/26/a-programmers-guide-to-the-central-limit-theorem.html" title="A Programmer's Guide to the Central Limit Theorem">&larr; A Programmer's Guide to the Central Limit Theorem</a></span>
    
    
      <span class="next"><a href="/2013/09/09/the-3-things-you-should-understand-about-quantum-computing.html" title="The 3 Things You Should Understand about Quantum Computation">The 3 Things You Should Understand about Quantum Computation &rarr;</a></span>
    
      <div style="clear: both"></div>
    </div>
    <hr>
    


  <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'jliszka'; // required: replace example with your forum shortname
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>




  </div>

  <div class="span2 sidebar">
    <a href="/"><div id="photo"></div></a>
    <div id="bio">
      <b>Jason Liszka</b><br/>
      <i>Software engineer at Foursquare, CMU alum, Scala fan, new father</i>
    </div>
    <h4>Popular posts</h4>
    <ul>
      <li><a href="/2013/10/01/how-traffic-actually-works.html">How traffic actually works</a></li>
      <li><a href="/2013/08/12/a-frequentist-approach-to-probability.html">A frequentist approach to probability</a></li>
      <li><a href="/2013/10/24/exact-numeric-nth-derivatives.html">Exact numeric nth derivatives</a></li>
      <li><a href="/2013/10/31/infinite-lazy-polynomials.html">Infinite lazy polynomials</a></li>
    </ul>

    <h4>Recent posts</h4>
    <ul>
      
        <li><a href="/2014/07/12/is-the-nba-draft-rigged.html">Is the NBA draft rigged?</a></li>
      
        <li><a href="/2014/06/03/programming-with-futures.html">Programming with futures: patterns and anti-patterns</a></li>
      
        <li><a href="/2014/01/30/good-tech-lead-bad-tech-lead.html">Good Tech Lead, Bad Tech Lead</a></li>
      
        <li><a href="/2013/12/18/bayesian-networks-and-causality.html">Bayesian networks and causality</a></li>
      
        <li><a href="/2013/11/22/unlikely-things-happen-all-the-time.html">Unlikely things happen all the time</a></li>
      
    </ul>

    <a href="https://twitter.com/jliszka" class="twitter-follow-button" data-show-count="false" data-size="large" data-show-screen-name="false">Follow @jliszka</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  </div>
</div>


      </div>
      <hr>
      <footer>
        <p>&copy; 2014 Jason Liszka
          with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a>
          and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a>
        </p>
      </footer>

    </div>

    


  <script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-42567355-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>



  </body>
</html>

