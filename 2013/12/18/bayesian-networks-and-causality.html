
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Bayesian networks and causality</title>
    <meta name="description" content="">
    <meta name="author" content="Jason Liszka">

    <!-- Enable responsive viewport -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.2.2.2.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css?body=1&amp;v=2" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/twitter/css/pygment.css" rel="stylesheet" type="text/css" media="all">

    <!-- Le fav and touch icons -->
  <!-- Update these with your own images
    <link rel="shortcut icon" href="images/favicon.ico">
    <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
  -->

    <!-- atom & rss feed -->
    <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  </head>

  <body>
    <div class="navbar">
      <div class="navbar-inner">
        <div class="container-narrow">
          <div class="row-fluid">
            <div class="span9 offset1">
              <a class="brand" href="/">A Gentleman and a Scala</a>
              <ul class="nav">
                
                
                


  
    
      
      	
      	<li><a href="/archive.html">Archive</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/tags.html">Tags</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  



              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-narrow">

      <div class="content">
        
<div class="row-fluid">
  <div class="span9 offset1 post-content post-spacer"></div>
</div>
<div class="row-fluid post-full">
  <div class="span9 offset1 post-content">
    <div class="page-header">
      <h1>Bayesian networks and causality </h1>
    </div>
    <div class="date">
      <span>18 December 2013</span>
    </div>
    <div class="content">
      
<p>Correlation does not imply causality—you’ve heard it a thousand times. But causality does imply correlation. Being
good Bayesians, we should know how to turn a statement like that around and find a way to infer causality from
correlation.</p>

<p>The tool we’re going to use to do this is called a <a href="http://en.wikipedia.org/wiki/Graphical_model">probabilistic graphical model</a>.
A PGM is a graph that encodes the causal relationships between events. For example, you might construct this
graph to model a chain of causes resulting in someone getting a college scholarship:</p>

<p><img src="/assets/img/pgm/sat.png" alt="A -&gt; B -&gt; C" /></p>

<p>Or the relationship between diseases and their symptoms:</p>

<p><img src="/assets/img/pgm/flu.png" alt="A &lt;- B -&gt; C" /></p>

<p>Or the events surrounding a traffic jam:</p>

<p><img src="/assets/img/pgm/trafficjam.png" alt="A -&gt; B &lt;- C -&gt; D" /></p>

<p>Each node represents a random variable, and the arrows represent dependence relations between them. You can think of
a node with incoming arrows as a probability distribution parameterized on some set of inputs; in other words,
a function from some set of inputs to a probability distribution.</p>

<p>PGMs with directed edges and no cycles are specifically called <a href="http://en.wikipedia.org/wiki/Bayesian_network">Bayesian networks</a>,
and that’s the kind of PGM I’m going to focus on.</p>

<p>It’s easy to translate a Bayesian network into code using this <a href="https://github.com/jliszka/probability-monad">toy probability library</a>.
All we need are the observed frequencies for each node and its inputs.
Let’s try the traffic jam graph. I’ll make up some numbers and we’ll see how it works.</p>

<!-- more -->

<p>Let’s start with the nodes with no incoming arrows.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rushHour</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">Boolean</span><span class="o">]</span> <span class="k">=</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.2</span><span class="o">)</span>
<span class="k">val</span> <span class="n">badWeather</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">Boolean</span><span class="o">]</span> <span class="k">=</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.05</span><span class="o">)</span></code></pre></div>

<p>In this hypothetical world, 20% of the time it’s rush hour, and 5% of the time there’s bad weather.</p>

<p>For nodes with incoming arrows, we return a different distribution depending on the particular value its
in-neighbor takes.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">accident</span><span class="o">(</span><span class="n">badWeather</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">)</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">Boolean</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="n">badWeather</span> <span class="k">match</span> <span class="o">{</span>
    <span class="k">case</span> <span class="kc">true</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.3</span><span class="o">)</span>
    <span class="k">case</span> <span class="kc">false</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>

<p>If the weather is bad, we’re 30% likely to see an accident, but otherwise accidents occur only 10% of the time.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">sirens</span><span class="o">(</span><span class="n">accident</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">)</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">Boolean</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="n">accident</span> <span class="k">match</span> <span class="o">{</span>
    <span class="k">case</span> <span class="kc">true</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.9</span><span class="o">)</span>
    <span class="k">case</span> <span class="kc">false</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.2</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>

<p>Straightforward enough.</p>

<p>Now let’s tackle <code>trafficJam</code>. It’s going to have 3 <code>Boolean</code> inputs, and we’ll need
to return a different probabilty distribution depending on which of the inputs are true. Let’s say that
if any two of of the inputs are true, there’s a 95% chance of a traffic jam, and that
traffic jams are less likely if only one of them is true, and somewhat unlikely if none are.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">trafficJam</span><span class="o">(</span><span class="n">rushHour</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">,</span>
               <span class="n">badWeather</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">,</span>
               <span class="n">accident</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">)</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">Boolean</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">rushHour</span><span class="o">,</span> <span class="n">badWeather</span><span class="o">,</span> <span class="n">accident</span><span class="o">)</span> <span class="k">match</span> <span class="o">{</span>
    <span class="k">case</span> <span class="o">(</span><span class="kc">true</span><span class="o">,</span> <span class="kc">true</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.95</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="kc">true</span><span class="o">,</span> <span class="k">_</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.95</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="kc">true</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.95</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="kc">true</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.5</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="kc">false</span><span class="o">,</span> <span class="kc">true</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.3</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="kc">false</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.6</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="kc">false</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>

<p>If you’ve done any Scala or Haskell programming, you’ve probably noticed that these are all functions of type
<code>A =&gt; Distribution[B]</code>—and yeah, you better believe we’re gonna <code>flatMap</code> that shit.</p>

<p>So let’s wire everything up and produce the joint probability distribution for all these events.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">Traffic</span><span class="o">(</span>
  <span class="n">rushHour</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">,</span>
  <span class="n">badWeather</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">,</span>
  <span class="n">accident</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">,</span>
  <span class="n">sirens</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">,</span>
  <span class="n">trafficJam</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">)</span>

<span class="k">val</span> <span class="n">traffic</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">Traffic</span><span class="o">]</span> <span class="k">=</span> <span class="k">for</span> <span class="o">{</span>
  <span class="n">r</span> <span class="k">&lt;-</span> <span class="n">rushHour</span>
  <span class="n">w</span> <span class="k">&lt;-</span> <span class="n">badWeather</span>
  <span class="n">a</span> <span class="k">&lt;-</span> <span class="n">accident</span><span class="o">(</span><span class="n">w</span><span class="o">)</span>
  <span class="n">s</span> <span class="k">&lt;-</span> <span class="n">sirens</span><span class="o">(</span><span class="n">a</span><span class="o">)</span>
  <span class="n">t</span> <span class="k">&lt;-</span> <span class="n">trafficJam</span><span class="o">(</span><span class="n">r</span><span class="o">,</span> <span class="n">w</span><span class="o">,</span> <span class="n">a</span><span class="o">)</span>
<span class="o">}</span> <span class="k">yield</span> <span class="nc">Traffic</span><span class="o">(</span><span class="n">r</span><span class="o">,</span> <span class="n">w</span><span class="o">,</span> <span class="n">a</span><span class="o">,</span> <span class="n">s</span><span class="o">,</span> <span class="n">t</span><span class="o">)</span></code></pre></div>

<p>Now we can query this distribution to see what affects what.</p>

<p>Say you’re about to head home from work and you notice it’s raining pretty hard. What’s the chance there’s a traffic jam?</p>

<pre><code>scala&gt; traffic.given(_.badWeather).pr(_.trafficJam)
res0: Double = 0.5658
</code></pre>

<p>Then you hear sirens.</p>

<pre><code>scala&gt; traffic.given(_.badWeather).given(_.sirens).pr(_.trafficJam)
res1: Double = 0.6718
</code></pre>

<p>About what you’d expect. Sirens increases your belief that there’s an accident, which will in turn affect the traffic.</p>

<p>Let’s look at things the other way around. Say you’re sitting in traffic and you want to know whether there’s
an accident up ahead.</p>

<pre><code>scala&gt; traffic.given(_.trafficJam).pr(_.accident)
res2: Double = 0.3183
</code></pre>

<p>Also, it’s raining, so you decide to factor that in:</p>

<pre><code>scala&gt; traffic.given(_.trafficJam).given(_.badWeather).pr(_.accident)
res3: Double = 0.4912
</code></pre>

<p>Makes sense, bad weather increases the chance of an accident.</p>

<p>Suppose instead the weather is fine, but it is rush hour:</p>

<pre><code>scala&gt; traffic.given(_.trafficJam).given(_.rushHour).pr(_.accident)
res4: Double = 0.1807
</code></pre>

<p>That’s interesting, adding the knowledge that it’s rush hour made the likelihood that there’s an accident go down.
But there’s no direct causal link in our model between rush hour and accidents. What’s going on?</p>

<h3 id="belief-propagation">Belief propagation</h3>

<p>The neat thing about Bayesian networks is that they completely explain which nodes can be correlated and
which are independent. By following a few simple rules, you can read this information right off the graph.</p>

<p><strong>Rule 0.</strong> In the graph below, A and B can be correlated:</p>

<p><img src="/assets/img/pgm/ab.png" alt="A -&gt; B" /></p>

<p>It’s almost too simple to mention, but knowing the value of A will change your belief about the value of B.</p>

<p>What’s slightly less obvious is that knowing the value of B will change your belief about the value of A. For example,
if rain causes the sidewalk to be wet, then seeing a wet sidewalk changes your belief about whether it rained.</p>

<p><strong>Rule 1.</strong> In the graph below, A and B can be correlated:</p>

<p><img src="/assets/img/pgm/linear.png" alt="A -&gt; C -&gt; B" /></p>

<p>Knowing the value of A will change your belief about the value of B. Furthermore, knowing the value of B will also
change your belief about the value of A. Intuitively, if someone got a scholarship (B), that raises your belief about
whether they studied for their SATs (A), even if there’s an intermediate cause in the mix, say a high SAT score (C).</p>

<p>So far, it seems like belief can propagate through arrows in either direction.</p>

<p><strong>Rule 2.</strong> In the graph below, A and B can be correlated:</p>

<p><img src="/assets/img/pgm/fork.png" alt="A &lt;- C -&gt; B" /></p>

<p>Knowing the value of A influences your belief about the value of C,
which directly affects the value of B. For example, knowing that someone has a fever (A) increases your belief that
they have the flu (C), which in turn increases your belief that they have a sore throat (B).</p>

<p>So what’s the point of arrows if belief can propagate across them in either direction? Glad you asked.</p>

<p><strong>Rule 3.</strong> In the graph below, A and B must be independent:</p>

<p><img src="/assets/img/pgm/join.png" alt="A -&gt; C &lt;- B" /></p>

<p>To give you the intuition, whether the weather is bad (A) should have no influence over
whether it’s currently rush hour (B), even though they both cause traffic jams (C).</p>

<p>So we have two cases where belief can propagate through a node, and one case where it can’t. But something interesting
happens when the value of the middle node, C, is known—the situation completely reverses.</p>

<h3 id="belief-propagation-with-observed-nodes">Belief propagation with observed nodes</h3>

<p><strong>Rule 1a.</strong> In the graph below, if C is known, A and B must be independent.</p>

<p><img src="/assets/img/pgm/linear-c.png" alt="A -&gt; C -&gt; B" /></p>

<p>Knowing C “blocks” belief from propagating from A to B. If you know that someone got a high SAT score (C), whether they
studied for their SATs (A) doesn’t tell you anything new about whether they got a scholarship (B). In the reverse case,
if you know that someone got a high SAT score, then knowing whether or not they got a scholarship should not change your
belief about whether or not they studied.</p>

<p><strong>Rule 2a.</strong> In the graph below, if C is known, A and B must be independent.</p>

<p><img src="/assets/img/pgm/fork-c.png" alt="A &lt;- C -&gt; B" /></p>

<p>Again, knowledge of the middle node blocks belief from propagating through it. If you know someone has the flu (C),
knowing that they have a sore throat (A) does not affect your belief that they have a fever (B); knowing that they have
the flu already tells you everything you need to know about their body temperature.</p>

<p><strong>Rule 3a.</strong> In the graph below, if C is known, A and B can be correlated.</p>

<p><img src="/assets/img/pgm/join-c.png" alt="A -&gt; C &lt;- B" /></p>

<p>This case is interesting—normally, belief would not be able to propagate through node C like this, but if its value is
known, the node becomes “activated” and belief can flow through. The intuition here is that if I already know that
there’s a traffic jam (C), then knowing that it’s rush hour (A) should <em>decrease</em> my belief that the weather is bad
(B). Rush hour “explains away” the traffic jam, making bad weather seem less likely.</p>

<p><strong>Rule 3b.</strong> In the graph below, if D is known, A and B can be correlated.</p>

<p><img src="/assets/img/pgm/join-cd.png" alt="A -&gt; CD &lt;- B" /></p>

<p>This rule is a variation on Rule 3a. If we know D, then we also know something about C, which partially activates C and
allows belief to flow through it from A to B. For example, if I observe someone wearing a college sweatshirt (D), that
increases my belief that they went to college (C). If I find out that they got a high SAT score (A), that can decrease
my belief that they played sports (B).</p>

<p>These rules are collectively known as the <a href="http://mlg.eng.cam.ac.uk/zoubin/course03/BayesBall.pdf">Bayes-Ball algorithm</a>.
There’s no Dr. Ball; it’s just a pun on “baseball.” Statistics jokes: they’re probably funny!</p>

<p>Anyway, now that we have some rules, let’s put them to use.</p>

<h3 id="are-coin-flips-independent">Are coin flips independent?</h3>

<p>Everyone knows that coin flips are independent of one another—if you flip a fair coin 10 times and it comes up heads each
time, the probability that it will come up heads on the next flip is stil 50%.</p>

<p>But here’s a different argument: If I flip a coin 100 times and it comes up heads 85 times, I might notice that this is
astronomically unlikely under the assumption that I have a fair coin, and call shenanigans on the whole thing. I could
then reasonably conclude that the coin’s bias is actually 85%, in which case the next flip is maybe 85% likely to come up
heads—meaning the next flip was <em>not</em> independent of the other flips!</p>

<p>How can we reconcile these two arguments? There’s a subtle difference between the two that becomes clear when you
draw out the graph.</p>

<p>Here’s the first case:</p>

<p><img src="/assets/img/pgm/coin-b.png" alt="coin bias known" /></p>

<p>The bias is known (50%), so belief is blocked from propagating between the individual flips (Rule 2a).</p>

<p>Here’s the second case:</p>

<p><img src="/assets/img/pgm/coin.png" alt="coin bias unknown" /></p>

<p>Here, the bias is unknown, so belief is allowed to flow through the “bias” node (Rule 2).</p>

<p>So both are right! They just make subtly different assumptions.</p>

<h3 id="reasoning-about-hidden-nodes">Reasoning about hidden nodes</h3>

<p>The Bayesian network below represents the blood types of several members of a family. The shaded nodes indicate nodes we
can’t observe. But as long as we know how they interact with the observable nodes, we can make inferences about how the
observable nodes interact with each other.</p>

<p><img src="/assets/img/pgm/bloodtypes.png" alt="blood types" /></p>

<p>This will be pretty fun to code up. Here’s how we’ll represent the genotypes and phenotypes (blood types):</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">sealed</span> <span class="k">trait</span> <span class="nc">BloodGene</span>
<span class="k">case</span> <span class="k">object</span> <span class="nc">A_</span> <span class="k">extends</span> <span class="nc">BloodGene</span>
<span class="k">case</span> <span class="k">object</span> <span class="nc">B_</span> <span class="k">extends</span> <span class="nc">BloodGene</span>
<span class="k">case</span> <span class="k">object</span> <span class="nc">O_</span> <span class="k">extends</span> <span class="nc">BloodGene</span>

<span class="k">sealed</span> <span class="k">trait</span> <span class="nc">BloodType</span>
<span class="k">case</span> <span class="k">object</span> <span class="nc">A</span> <span class="k">extends</span> <span class="nc">BloodType</span>
<span class="k">case</span> <span class="k">object</span> <span class="nc">B</span> <span class="k">extends</span> <span class="nc">BloodType</span>
<span class="k">case</span> <span class="k">object</span> <span class="nc">AB</span> <span class="k">extends</span> <span class="nc">BloodType</span>
<span class="k">case</span> <span class="k">object</span> <span class="nc">O</span> <span class="k">extends</span> <span class="nc">BloodType</span></code></pre></div>

<p>Yeah, I know, Scala makes this unnecessarily verbose.</p>

<p>For the arrows linking each person’s genes to their blood type, we need a function that determines <code>BloodType</code> given
two <code>BloodGene</code>s. This happens to be a deterministic function, but I’m implementing it as a stochastic function anyway.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">typeFromGene</span><span class="o">(</span><span class="n">g</span><span class="k">:</span> <span class="o">(</span><span class="kt">BloodGene</span><span class="o">,</span> <span class="kt">BloodGene</span><span class="o">))</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">BloodType</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="n">g</span> <span class="k">match</span> <span class="o">{</span>
    <span class="k">case</span> <span class="o">(</span><span class="nc">A_</span><span class="o">,</span> <span class="nc">B_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">always</span><span class="o">(</span><span class="nc">AB</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="nc">B_</span><span class="o">,</span> <span class="nc">A_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">always</span><span class="o">(</span><span class="nc">AB</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="nc">A_</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">always</span><span class="o">(</span><span class="n">A</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="nc">A_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">always</span><span class="o">(</span><span class="n">A</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="nc">B_</span><span class="o">,</span> <span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">always</span><span class="o">(</span><span class="n">B</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="nc">B_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">always</span><span class="o">(</span><span class="n">B</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="nc">O_</span><span class="o">,</span> <span class="nc">O_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">always</span><span class="o">(</span><span class="n">O</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>

<p>For the arrows linking parents’ genes to their children’s genes, we can implement this function that chooses one
gene from each parent at random:</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">childFromParents</span><span class="o">(</span><span class="n">p1</span><span class="k">:</span> <span class="o">(</span><span class="kt">BloodGene</span><span class="o">,</span> <span class="kt">BloodGene</span><span class="o">),</span>
                     <span class="n">p2</span><span class="k">:</span> <span class="o">(</span><span class="kt">BloodGene</span><span class="o">,</span> <span class="kt">BloodGene</span><span class="o">))</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[(</span><span class="kt">BloodGene</span>, <span class="kt">BloodGene</span><span class="o">)]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="o">(</span><span class="n">p1a</span><span class="o">,</span> <span class="n">p1b</span><span class="o">)</span> <span class="k">=</span> <span class="n">p1</span>
  <span class="k">val</span> <span class="o">(</span><span class="n">p2a</span><span class="o">,</span> <span class="n">p2b</span><span class="o">)</span> <span class="k">=</span> <span class="n">p2</span>
  <span class="n">discreteUniform</span><span class="o">(</span><span class="k">for</span> <span class="o">{</span>
    <span class="n">p1</span> <span class="k">&lt;-</span> <span class="nc">List</span><span class="o">(</span><span class="n">p1a</span><span class="o">,</span> <span class="n">p1b</span><span class="o">)</span>
    <span class="n">p2</span> <span class="k">&lt;-</span> <span class="nc">List</span><span class="o">(</span><span class="n">p2a</span><span class="o">,</span> <span class="n">p2b</span><span class="o">)</span>
  <span class="o">}</span> <span class="k">yield</span> <span class="o">(</span><span class="n">p1</span><span class="o">,</span> <span class="n">p2</span><span class="o">))</span>
<span class="o">}</span></code></pre></div>

<p>Finally, for the people whose parents are not specified, we supply a prior on each of the 3 genes refecting their
<a href="http://en.wikipedia.org/wiki/Blood_type_distribution_by_country">prevalence in the general population</a>.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">bloodGenePrior</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[(</span><span class="kt">BloodGene</span>, <span class="kt">BloodGene</span><span class="o">)]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">geneFrequencies</span> <span class="k">=</span> <span class="n">discrete</span><span class="o">(</span><span class="nc">A_</span> <span class="o">-&gt;</span> <span class="mf">0.26</span><span class="o">,</span> <span class="nc">B_</span> <span class="o">-&gt;</span> <span class="mf">0.08</span><span class="o">,</span> <span class="nc">O_</span> <span class="o">-&gt;</span> <span class="mf">0.66</span><span class="o">)</span>
  <span class="k">for</span> <span class="o">{</span>
    <span class="n">g1</span> <span class="k">&lt;-</span> <span class="n">geneFrequencies</span>
    <span class="n">g2</span> <span class="k">&lt;-</span> <span class="n">geneFrequencies</span>
  <span class="o">}</span> <span class="k">yield</span> <span class="o">(</span><span class="n">g1</span><span class="o">,</span> <span class="n">g2</span><span class="o">)</span>
<span class="o">}</span></code></pre></div>

<p>OK, now let’s wire everything up. This should be a straightforward translation of the Bayesian network above into code.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">BloodTrial</span><span class="o">(</span><span class="n">lisa</span><span class="k">:</span> <span class="kt">BloodType</span><span class="o">,</span> <span class="n">homer</span><span class="k">:</span> <span class="kt">BloodType</span><span class="o">,</span> <span class="n">marge</span><span class="k">:</span> <span class="kt">BloodType</span><span class="o">,</span>
                      <span class="n">selma</span><span class="k">:</span> <span class="kt">BloodType</span><span class="o">,</span> <span class="n">jackie</span><span class="k">:</span> <span class="kt">BloodType</span><span class="o">,</span> <span class="n">harry</span><span class="k">:</span> <span class="kt">BloodType</span><span class="o">)</span>

<span class="k">val</span> <span class="n">bloodType</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">BloodTrial</span><span class="o">]</span> <span class="k">=</span> <span class="k">for</span> <span class="o">{</span>
  <span class="n">gHomer</span> <span class="k">&lt;-</span> <span class="n">bloodGenePrior</span>
  <span class="n">gHarry</span> <span class="k">&lt;-</span> <span class="n">bloodGenePrior</span>
  <span class="n">gJackie</span> <span class="k">&lt;-</span> <span class="n">bloodGenePrior</span>
  <span class="n">gSelma</span> <span class="k">&lt;-</span> <span class="n">childFromParents</span><span class="o">(</span><span class="n">gHarry</span><span class="o">,</span> <span class="n">gJackie</span><span class="o">)</span>
  <span class="n">gMarge</span> <span class="k">&lt;-</span> <span class="n">childFromParents</span><span class="o">(</span><span class="n">gHarry</span><span class="o">,</span> <span class="n">gJackie</span><span class="o">)</span>
  <span class="n">gLisa</span> <span class="k">&lt;-</span> <span class="n">childFromParents</span><span class="o">(</span><span class="n">gHomer</span><span class="o">,</span> <span class="n">gMarge</span><span class="o">)</span>
  <span class="n">bLisa</span> <span class="k">&lt;-</span> <span class="n">typeFromGene</span><span class="o">(</span><span class="n">gLisa</span><span class="o">)</span>
  <span class="n">bHomer</span> <span class="k">&lt;-</span> <span class="n">typeFromGene</span><span class="o">(</span><span class="n">gHomer</span><span class="o">)</span>
  <span class="n">bMarge</span> <span class="k">&lt;-</span> <span class="n">typeFromGene</span><span class="o">(</span><span class="n">gMarge</span><span class="o">)</span>
  <span class="n">bSelma</span> <span class="k">&lt;-</span> <span class="n">typeFromGene</span><span class="o">(</span><span class="n">gSelma</span><span class="o">)</span>
  <span class="n">bJackie</span> <span class="k">&lt;-</span> <span class="n">typeFromGene</span><span class="o">(</span><span class="n">gJackie</span><span class="o">)</span>
  <span class="n">bHarry</span> <span class="k">&lt;-</span> <span class="n">typeFromGene</span><span class="o">(</span><span class="n">gHarry</span><span class="o">)</span>
<span class="o">}</span> <span class="k">yield</span> <span class="nc">BloodTrial</span><span class="o">(</span><span class="n">bLisa</span><span class="o">,</span> <span class="n">bHomer</span><span class="o">,</span> <span class="n">bMarge</span><span class="o">,</span> <span class="n">bSelma</span><span class="o">,</span> <span class="n">bJackie</span><span class="o">,</span> <span class="n">bHarry</span><span class="o">)</span></code></pre></div>

<p>Here it is in action:</p>

<pre><code>scala&gt; bloodType.map(_.marge).hist
 A 40.40% ########################################
 B 11.19% ###########
AB  4.25% ####
 O 44.16% ############################################

scala&gt; bloodType.given(_.lisa == B).map(_.marge).hist
 A 12.65% ############
 B 42.98% ##########################################
AB 13.32% #############
 O 31.05% ###############################

scala&gt; bloodType.given(_.lisa == AB).map(_.marge).hist
 A 45.71% #############################################
 B 37.40% #####################################
AB 16.89% ################
</code></pre>

<p>Makes sense so far. Let’s look at Lisa and her Aunt Selma:</p>

<pre><code>scala&gt; bloodType.map(_.lisa).hist
 A 41.79% #########################################
 B 11.24% ###########
AB  3.94% ###
 O 43.03% ###########################################

scala&gt; bloodType.given(_.selma == A).map(_.lisa).hist
 A 52.82% ####################################################
 B  7.47% #######
AB  4.90% ####
 O 34.81% ##################################

scala&gt; bloodType.given(_.selma == B).map(_.lisa).hist
 A 26.84% ##########################
 B 27.22% ###########################
AB  9.08% #########
 O 36.86% ####################################
</code></pre>

<p>Homer and Marge should not affect each other, unless Lisa’s blood type is known:</p>

<pre><code>scala&gt; bloodType.map(_.homer).hist
 A 40.34% ########################################
 B 10.74% ##########
AB  4.21% ####
 O 44.71% ############################################

scala&gt; bloodType.given(_.marge == A).map(_.homer).hist
 A 40.60% ########################################
 B 10.83% ##########
AB  3.91% ###
 O 44.66% ############################################

scala&gt; bloodType.given(_.lisa == B).map(_.homer).hist
 A 11.91% ###########
 B 42.84% ##########################################
AB 13.77% #############
 O 31.48% ###############################

scala&gt; bloodType.given(_.lisa == B).given(_.marge == A).map(_.homer).hist
 B 73.99% #########################################################################
AB 26.01% ##########################
</code></pre>

<p>This is Rule 3b in effect. Even Harry and Jackie are correlated if their grandchild’s blood type is known:</p>

<pre><code>scala&gt; bloodType.given(_.lisa == AB).map(_.harry).hist
 A 43.83% ###########################################
 B 23.51% #######################
AB 10.90% ##########
 O 21.76% #####################

scala&gt; bloodType.given(_.lisa == AB).given(_.jackie == O).map(_.harry).hist
 A 45.01% #############################################
 B 37.73% #####################################
AB 17.26% #################
</code></pre>

<p>This is pretty fun to play around with!</p>

<h3 id="causal-fallacies">Causal fallacies</h3>

<p>If you observe that two events A and B are correlated, you cannot determine the direction of causality from
observational data on these two events alone. Any of</p>

<p><img src="/assets/img/pgm/ab.png" alt="A -&gt; B" /></p>

<p>(“A causes B”) or</p>

<p><img src="/assets/img/pgm/ba.png" alt="A &lt;- B" /></p>

<p>(“B causes A”) or</p>

<p><img src="/assets/img/pgm/fork.png" alt="A &lt;- C -&gt; B" /></p>

<p>(“A and B have a common cause”) could explain the observed correlation. But there’s also this possibility:</p>

<p><img src="/assets/img/pgm/join-c.png" alt="A -&gt; C &lt;- B" /></p>

<p>where C is known. This is just a biased sample—you might conclude that academic ability interferes with athletic
ability after observing that they are inversely correlated, until you realize you only surveyed college students, and
that academic and athletic scholorships are quite common. But it’s neat that graphical models unify these causal
fallacies.</p>

<p>To go further, you could come up with crazy causal graphs that predict a correlation between A and B, but where
the causal link between A and B is non-trivial. For example, the graph below allows A and B to be correlated, but neither
directly causes the other, they don’t have a common cause, and although there is a biased sample, it appears to only
directly affect B.</p>

<p><img src="/assets/img/pgm/abcde.png" alt="A &lt;- C -&gt; D -&gt; E &lt;- B" /></p>

<h3 id="determining-causality">Determining causality</h3>

<p>This brings up an important question: if I observe some events and their frequencies, how can I figure out which of the
possible graphs I could draw is the correct one? Well, the great thing about Bayesian networks is that they <em>make testable predictions</em>.
In particular, for a given graph, if the independence relations that we now know how to read off of it do not bear
themselves out empirically, we can eliminate that graph as a possibility. We can also use common sense to rule out
graphs that make unphysical predictions, for example, the sidewalk being wet causes it to rain, and effects preceding
their causes in general.</p>

<p>To take an example, the graph</p>

<p><img src="/assets/img/pgm/join.png" alt="A -&gt; C &lt;- B" /></p>

<p>predicts that A and B are independent, unless C is known. If we observe that, say,
<script type="math/tex">P(A=\text{true}|B=\text{true}) \gt P(A=\text{true})</script>, then we can rule out that graph as a possible model.</p>

<p>Usually we can use observations like this to narrow down the set of possible graphs. With only 2 events
to observe, there’s no way to distinguish <script type="math/tex">A \rightarrow B</script> and <script type="math/tex">A \leftarrow B</script> just from the data.
With 3 events that are all dependent, you can’t distinguish between <script type="math/tex">A \rightarrow B \rightarrow C</script> and
<script type="math/tex">A \leftarrow B \leftarrow C</script> and <script type="math/tex">A \leftarrow B \rightarrow C</script>.
However, you can distinguish <script type="math/tex">A \rightarrow B \rightarrow C</script> from <script type="math/tex">B \rightarrow A \rightarrow C</script>,
since in the first case, <script type="math/tex">A</script> and <script type="math/tex">C</script> are independent when you control for <script type="math/tex">B</script>.</p>

<p>If you’re lucky, you can narrow down the set of possible graphs enough to be able to infer what arrows there are
and what direction they point in. And before you know it, you’ve inferred causality from mere correlation. Voilà!</p>

<p>In practice, though, this rarely happens, especially if you have more than like 5 nodes in your graph. There are simply
too many possible graphs to consider, and the very connected ones don’t make any predictions at all that might help us
falsify them. But if you can step in and control things a bit, you can simplify the interactions and make the problem
tractable again.</p>

<h3 id="controlled-experiments">Controlled experiments</h3>

<p>Suppose you’re trying to decide whether playing a musical instrument results in higher SAT scores. In your
empirical observations you’re careful to identify socioeconomic status as a possible confounding factor. Say you end up
with the following 2 possible graphs:</p>

<p><img src="/assets/img/pgm/sat1.png" alt="SAT 1" /></p>

<p>You want to know whether the arrow from “plays music” to “high SAT score” exists or not. One thing you can try is to
control for socioeconomic status:</p>

<p><img src="/assets/img/pgm/sat2.png" alt="SAT 2" /></p>

<p>This prevents belief from propagating through the “high SES” node. If “plays music” and “high SAT score” are still
correlated after controlling for socioeconomic status, then you can eliminate the graph on the right and conclude that
there is a causal link between the two events. (Technically we don’t know which way the arrow should point, but that’s
where common sense steps in.) If “plays music” and “high SAT score” are independent when controlling for socioeconomic
status, then you have to reject the graph on the left and accept that there is no direct causal link between the events.</p>

<p>Socioeconomic status might not be the only confounding factor, though. There are a whole host of possible confounding
factors, and we can’t rule out the possibility that we missed one. So what we really have is this:</p>

<p><img src="/assets/img/pgm/sat3.png" alt="SAT 3" /></p>

<p>You can’t control for things you can’t observe. So in this case you have to step in and rewire things a bit:</p>

<p><img src="/assets/img/pgm/sat4.png" alt="SAT 4" /></p>

<p>By forcing “plays music” to be determined randomly and independent of anything else, you break the causal link between
it and any other confounding factors. Then it’s easy to determine whether the arrow between “plays music” and “high SAT score”
really exists.</p>

<p>But often this is not practical. In an example cribbed from
<a href="http://www.michaelnielsen.org/ddi/if-correlation-doesnt-imply-causation-then-what-does/">this excellent article on the subject</a>,
suppose you are trying to determine whether smoking causes lung cancer directly, or if instead there are some
environmental factors that happen to cause both. You have the following possible graphs:</p>

<p><img src="/assets/img/pgm/smoking1.png" alt="Smoking 1" /></p>

<p>You can’t step in and force some people to smoke or not smoke. You’d think we might be stuck here, but fortunately some
<a href="http://en.wikipedia.org/wiki/Judea_Pearl">extremely clever people</a> have figured out how to infer causality in a
situation like this without needing to run a controlled experiment. In this example, if you are able to hypothesize some
observable intermediate cause, such as the presence of tar in someone’s lungs:</p>

<p><img src="/assets/img/pgm/smoking2.png" alt="Smoking 2" /></p>

<p>then through a series of formal manipulations, you can arrive at a graph that, weirdly enough, looks like this:</p>

<p><img src="/assets/img/pgm/smoking3.png" alt="Smoking 3" /></p>

<p>The two “smokes” nodes have the same probability distribution but are independent from one another.</p>

<p>This is pretty great! Using the “smokes” node on the bottom, we can now ask this graph about the probability of someone
getting cancer, as if their decision to smoke was independent of any other factors. In other words, we can now determine
<em>what would have happened</em> if we had been able to force our subjects to smoke or not smoke in a controlled experiment.</p>

<p>Before we do that, though, we’re going to need to make one more little change—as it is, we’re going to run into trouble
with the “???” node. Since this node represents unknown causes in our model, we’re not going to be able to
observe it or its effects on other nodes. Fortunately, due to the magic of the Bayes-Ball rules, we can replace it with an
arrow that goes directly from “smokes” to “cancer”, without changing the meaning of the graph. So our two graphs become:</p>

<p><img src="/assets/img/pgm/smoking4.png" alt="Smoking 4" /></p>

<p>Now all of our nodes and arrows are observable, and we can go ahead and code this up.</p>

<p>Suppose we observe that 50% of the population smokes. We’ll have:</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">smokes</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">Boolean</span><span class="o">]</span> <span class="k">=</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.5</span><span class="o">)</span></code></pre></div>

<p>We can also encode observations of the frequencies at which smokers and non-smokers have tar in their lungs:</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">tar</span><span class="o">(</span><span class="n">smokes</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">)</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">Boolean</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="n">smokes</span> <span class="k">match</span> <span class="o">{</span>
    <span class="k">case</span> <span class="kc">true</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.95</span><span class="o">)</span>
    <span class="k">case</span> <span class="kc">false</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.05</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>

<p>And the last one, observed frequencies of cancer, broken out by whether someone smokes or has tar in their lungs:</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">def</span> <span class="n">cancer</span><span class="o">(</span><span class="n">smokes</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">,</span> <span class="n">tar</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">)</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">Boolean</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">smokes</span><span class="o">,</span> <span class="n">tar</span><span class="o">)</span> <span class="k">match</span> <span class="o">{</span>
    <span class="k">case</span> <span class="o">(</span><span class="kc">false</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="kc">true</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.9</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="kc">false</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.05</span><span class="o">)</span>
    <span class="k">case</span> <span class="o">(</span><span class="kc">true</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">tf</span><span class="o">(</span><span class="mf">0.85</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>

<p>Again, these numbers represent simple observed frequencies. We could actually do this in practice if we had experimental
data. (Obviously all the numbers here are extrememly made up.)</p>

<p>Now let’s wire everything together. We’ll do it two ways: the first way encoding the original graph, and the second way
encoding the manipulated graph that separates “smokes” from external influences.</p>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">SmokingTrial</span><span class="o">(</span><span class="n">smokes</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">,</span> <span class="n">tar</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">,</span> <span class="n">cancer</span><span class="k">:</span> <span class="kt">Boolean</span><span class="o">)</span>

<span class="k">def</span> <span class="n">smoking1</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">SmokingTrial</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">for</span> <span class="o">{</span>
    <span class="n">s</span> <span class="k">&lt;-</span> <span class="n">smokes</span>
    <span class="n">t</span> <span class="k">&lt;-</span> <span class="n">tar</span><span class="o">(</span><span class="n">s</span><span class="o">)</span>
    <span class="n">c</span> <span class="k">&lt;-</span> <span class="n">cancer</span><span class="o">(</span><span class="n">s</span><span class="o">,</span> <span class="n">t</span><span class="o">)</span>
  <span class="o">}</span> <span class="k">yield</span> <span class="nc">SmokingTrial</span><span class="o">(</span><span class="n">s</span><span class="o">,</span> <span class="n">t</span><span class="o">,</span> <span class="n">c</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">def</span> <span class="n">smoking2</span><span class="k">:</span> <span class="kt">Distribution</span><span class="o">[</span><span class="kt">SmokingTrial</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">for</span> <span class="o">{</span>
    <span class="n">s1</span> <span class="k">&lt;-</span> <span class="n">smokes</span>
    <span class="n">s2</span> <span class="k">&lt;-</span> <span class="n">smokes</span>
    <span class="n">t</span> <span class="k">&lt;-</span> <span class="n">tar</span><span class="o">(</span><span class="n">s1</span><span class="o">)</span>
    <span class="n">c</span> <span class="k">&lt;-</span> <span class="n">cancer</span><span class="o">(</span><span class="n">s2</span><span class="o">,</span> <span class="n">t</span><span class="o">)</span>
  <span class="o">}</span> <span class="k">yield</span> <span class="nc">SmokingTrial</span><span class="o">(</span><span class="n">s1</span><span class="o">,</span> <span class="n">t</span><span class="o">,</span> <span class="n">c</span><span class="o">)</span>
<span class="o">}</span></code></pre></div>

<p>Now let’s see it in action.</p>

<pre><code>scala&gt; smoking1.pr(_.cancer)
res0: Double = 0.4723

scala&gt; smoking1.given(_.smokes).pr(_.cancer)
res1: Double = 0.8576

scala&gt; smoking2.pr(_.cancer)
res2: Double = 0.4759

scala&gt; smoking2.given(_.smokes).pr(_.cancer)
res3: Double = 0.4577
</code></pre>

<p>According to these made-up numbers, smoking actually <em>prevents</em> cancer,
even though empirically, smokers have a higher incidence of cancer than the general population!</p>

<p>This is pretty miraculous, if you ask me.</p>

<h3 id="further-reading">Further reading</h3>

<p><a href="http://lesswrong.com/lw/ev3/causal_diagrams_and_causal_models/">Less Wrong</a> has a great introduction on using Bayesian
newtworks and the predictions they make to determine the direction of causality.</p>

<p>Here are some slides from lectures on <a href="http://www.cs.nyu.edu/~roweis/csc412-2004/notes/lec2x.pdf">the Bayes-Ball algorithm</a>
and <a href="http://www.cs.columbia.edu/~jebara/4771/notes/class14x.pdf">how a Bayesian network factors a joint probability distribution</a>.</p>

<p>You should also read <a href="http://www.michaelnielsen.org/ddi/if-correlation-doesnt-imply-causation-then-what-does/">Michael Nielsen’s fantastic article</a>
explaining Judea Pearl’s work on simulating controlled experiments in, like, the nineties. This is cutting-edge stuff!
I bet you thought all of probability was worked out in the 1700s!</p>

<p>I also recommend the <a href="http://en.wikipedia.org/wiki/Graphical_model">Coursera on probabilistic graphical models</a>.</p>

<p>All of the code in this post is available in <a href="https://gist.github.com/jliszka/8017888">this gist</a>.</p>

<p>Thanks to <a href="https://twitter.com/metablake">Blake Shaw</a> for his feedback on early drafts of this post.</p>

    </div>

  

  


  <div style="float: right; margin-top: 5px">
  <a href="https://twitter.com/share" class="twitter-share-button" data-url="http://jliszka.github.io/2013/12/18/bayesian-networks-and-causality.html" data-text="Bayesian networks and causality" data-via="jliszka">Tweet</a>
  <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
</div>




  
    <ul class="tag_box inline">
      <li><i class="icon-tags"></i></li>
      
      


  
     
    	<li><a href="/tags.html#probability-ref">probability <span>10</span></a></li>
    
  



    </ul>
  
    <div style="clear: both"></div>

    <hr>
    <div class="navigation">
    
      <span class="prev"><a href="/2013/11/22/unlikely-things-happen-all-the-time.html" title="Unlikely things happen all the time">&larr; Unlikely things happen all the time</a></span>
    
    
      <span class="next"><a href="/2014/01/30/good-tech-lead-bad-tech-lead.html" title="Good Tech Lead, Bad Tech Lead">Good Tech Lead, Bad Tech Lead &rarr;</a></span>
    
      <div style="clear: both"></div>
    </div>
    <hr>
    


  <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'jliszka'; // required: replace example with your forum shortname
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>




  </div>

  <div class="span2 sidebar">
    <a href="/"><div id="photo"></div></a>
    <div id="bio">
      <b>Jason Liszka</b><br/>
      <i>Engineer at Slack NYC, CMU alum, Scala fan, new father</i>
    </div>
    <h4>Popular posts</h4>
    <ul>
      <li><a href="/2013/10/01/how-traffic-actually-works.html">How traffic actually works</a></li>
      <li><a href="/2013/08/12/a-frequentist-approach-to-probability.html">A frequentist approach to probability</a></li>
      <li><a href="/2013/10/24/exact-numeric-nth-derivatives.html">Exact numeric nth derivatives</a></li>
      <li><a href="/2013/10/31/infinite-lazy-polynomials.html">Infinite lazy polynomials</a></li>
    </ul>

    <h4>Recent posts</h4>
    <ul>
      
        <li><a href="/2016/04/05/probability-is-in-the-process.html">Probability is in the process</a></li>
      
        <li><a href="/2014/07/31/the-quantum-eraser.html">The quantum eraser demystified</a></li>
      
        <li><a href="/2014/07/12/is-the-nba-draft-rigged.html">Is the NBA draft rigged?</a></li>
      
        <li><a href="/2014/06/03/programming-with-futures.html">Programming with futures: patterns and anti-patterns</a></li>
      
        <li><a href="/2014/01/30/good-tech-lead-bad-tech-lead.html">Good Tech Lead, Bad Tech Lead</a></li>
      
    </ul>

    <a href="https://twitter.com/jliszka" class="twitter-follow-button" data-show-count="false" data-size="large" data-show-screen-name="false">Follow @jliszka</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  </div>
</div>


      </div>
      <hr>
      <footer>
        <p>&copy; 2016 Jason Liszka
          with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a>
          and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a>
        </p>
      </footer>

    </div>

    


  <script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-42567355-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>



  </body>
</html>

